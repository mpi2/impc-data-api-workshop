{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7c8e987-4016-4c94-bdf2-3f1e56ec596b",
   "metadata": {},
   "source": [
    "# International Mouse Phenotyping Consortium (IMPC) Data API Workshop\n",
    "Welcome to our workshop! In this session, we'll guide you through using Apache Solr API to access IMPC data. After that, we will focus on the `phenodigm` core. By the end, you'll confidently construct Solr queries to extract IMPC datasets. Get ready for hands-on exercises and real-world examples to reinforce your skills!\n",
    "\n",
    "For more information about IMPC visit our [website](https://www.mousephenotype.org/).\n",
    "Other useful links:\n",
    "- Workshop [repository](https://github.com/mpi2/impc-data-api-workshop/tree/main) with all materials\n",
    "- IMPC Solr cores [documentation](https://www.ebi.ac.uk/mi/impc/solrdoc/)\n",
    "- International Mouse Phenotyping Resource of Standardised Screens | [IMPReSS](https://www.mousephenotype.org/impress/index)\n",
    "- The Genome Targeting Repository | [GenTaR](https://www.gentar.org/tracker/#/)\n",
    "\n",
    "# Set up\n",
    "Let's start! First of all we need to import python libraries and set up helper function.\n",
    "### Helper functions\n",
    "Execute cell below. Follow steps:\n",
    "1. Select cell by clicking into it.\n",
    "2. Execute code by pressing â–· play button above.\n",
    "3. You can also use hotkey Ctrl + Enter to execute code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145b2ed3-97e9-4b8b-b780-b102dd6f3afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "from tqdm import tqdm\n",
    "from urllib.parse import unquote\n",
    "\n",
    "import csv\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "# Display the whole dataframe <15\n",
    "pd.set_option('display.max_rows', 15)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Create helper function\n",
    "def solr_request(core, params, silent=False):\n",
    "    \"\"\"Performs a single Solr request.\n",
    "    \n",
    "    Returns:\n",
    "        num_found: How many rows in total did the request match.\n",
    "        df: A Pandas dataframe with a portion of the request matching `start` and `rows` parameters.\n",
    "        silent: Suppress displaying the df and number of results (useful for batch requests).\n",
    "    \"\"\"\n",
    "    base_url = \"https://www.ebi.ac.uk/mi/impc/solr/\"\n",
    "    solr_url = base_url + core + \"/select\"\n",
    "\n",
    "    response = requests.get(solr_url, params=params)\n",
    "    if not silent:\n",
    "        print(f\"\\nYour request:\\n{response.request.url}\\n\")\n",
    "    \n",
    "    # Check if the request was successful (status code 200)\n",
    "    if response.status_code == 200:\n",
    "        # Parse the JSON response\n",
    "        data = response.json()\n",
    "        num_found = data[\"response\"][\"numFound\"]\n",
    "        if not silent:\n",
    "            print(f'Number of found documents: {num_found}\\n')\n",
    "        # Extract and add search results to the list\n",
    "        search_results = []\n",
    "        for doc in data[\"response\"][\"docs\"]:\n",
    "            search_results.append(doc)\n",
    "    \n",
    "        # Convert the list of dictionaries into a DataFrame and print the DataFrame\n",
    "        df = pd.DataFrame(search_results)\n",
    "        if not silent:\n",
    "            display(df)\n",
    "        return num_found, df\n",
    "    \n",
    "    else:\n",
    "        print(\"Error:\", response.status_code, response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab77d79-8e0b-46e4-bf60-027cc69e5525",
   "metadata": {},
   "source": [
    "### Example query\n",
    "We will use `solr_request` function to access IMPC data using Solr API. Let's run cell below and investigate the result.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf57a86-93ad-4694-a3ad-179bf1438519",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_found, df = solr_request(\n",
    "    core='genotype-phenotype',\n",
    "    params={\n",
    "        'q': '*:*',  # Your query, '*' retrieves all documents\n",
    "        'rows': 10,  # Number of rows to retrieve\n",
    "        'fl': 'marker_symbol,allele_symbol,parameter_stable_ide',  # Fields to retrieve\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c9ca60-9c63-4acc-a1ce-6bc3881fba35",
   "metadata": {},
   "source": [
    "Let's take a look at the output of helper function. You can see following:\n",
    "1. Submitted request, that you can open in browser by clicking into the link.\n",
    "2. Number of documents in the requested dataframe.\n",
    "3. Table with the results of your query. It will display less than 15 rows.\n",
    "\n",
    "Let's get started with the exercises!\n",
    "\n",
    "# Exercise block A\n",
    "\n",
    "### Exercise 1: Getting Familiar with the Core\n",
    "We will be working with `genotype-phenotype` core. To get yourself familiar with data, request 3 rows and all fields from this core.\n",
    "<br>\n",
    "<br>\n",
    "If you complete the exercise successfully, your total number of documents will be **67,660**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ddcef9-af7c-45f8-9ec9-4e3da168ab5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_found, df = solr_request(\n",
    "    core=...,\n",
    "    params={\n",
    "        'q': ...,\n",
    "        'rows': ...,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75179169-d80e-4d95-bdea-d3a88bb0d576",
   "metadata": {},
   "source": [
    "### Exercise 2: Selecting Specific Fields\n",
    "As you can see, there is a lot of fields. To focus on the fields we need, request only the following once:\n",
    "- marker_symbol\n",
    "- marker_accession_id\n",
    "- zygosity\n",
    "- parameter_name\n",
    "- parameter_stable_id\n",
    "- p_value\n",
    "<br>\n",
    "\n",
    "Modify query from exercise 1 to request limited list of the fields above.\n",
    "<br>\n",
    "<br>\n",
    "If you complete the exercise successfully, your total number of documents will be **67,660**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8b77fc-876a-43f7-a09d-ca4e0d2bb439",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_found, df = solr_request(\n",
    "    core='genotype-phenotype',\n",
    "    params={\n",
    "        'q': ...,\n",
    "        'rows': ...,\n",
    "        'fl': ...\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e092de-bf4d-42d0-8db2-762f61aea06c",
   "metadata": {},
   "source": [
    "# Exercise block B\n",
    "### Exercise 3: Filtering by Single Field\n",
    "Let's now focus on a particular gene. In this example we will be using *Dclk1*. Filter the results so there only documents of this gene are displayed by modifying query from exercise 2.\n",
    "<br>\n",
    "<br>\n",
    "If you complete the exercise successfully, your total number of documents will be **13**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5843d4fb-5057-468a-8538-85ecbd46c093",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_found, df = solr_request(\n",
    "    core='genotype-phenotype',\n",
    "    params={\n",
    "        'q': ...,\n",
    "        'rows': ...,\n",
    "        'fl': 'marker_symbol,marker_accession_id,zygosity,parameter_name,parameter_stable_id,p_value'\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1501dfa9-84e7-4733-b1f7-d92b6e49c935",
   "metadata": {},
   "source": [
    "### Exercise 4: Filtering Numerical Values and Applying Multiple Filters\n",
    "In addition to the `marker_symbol` filter, let's also apply more strict p-value threshold, so that it is less than 1e-4.\n",
    "<br>\n",
    "Modify query from exercise 3 and display **10 rows** instead of 3. \n",
    "<br>\n",
    "Note: Sometimes spelling may differ.\n",
    "<br>e.g. **`p_value`** is the name of the field in Solr, whereas **\"p-value\"** is the term used in real life.\n",
    "<br>\n",
    "<br>\n",
    "If you complete the exercise successfully, your total number of documents will be **5**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20e3749-73c3-4c1a-a98c-fce067471d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_found, df = solr_request(\n",
    "    core='genotype-phenotype',\n",
    "    params={\n",
    "        'q': ...,\n",
    "        'rows': ...,\n",
    "        'fl': 'marker_symbol,marker_accession_id,zygosity,parameter_name,parameter_stable_id,p_value'\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03cd8ff-2b64-4e4b-b389-9e69c4de29d7",
   "metadata": {},
   "source": [
    "### Exercise 5: Search for parameter stable ID in the IMPReSS and answer questions\n",
    "Follow steps below and answer the questions: \n",
    "1. Navigate to the [IMPReSS website](https://www.mousephenotype.org/impress/index).\n",
    "2. Search for the parameter_stable_id `IMPC_GRS_010_001`, which is referenced in Exercise 4.\n",
    "3. Examine the procedure associated with the pipeline key `IMPC_001` by clicking on the \"View procedure\" button.\n",
    "<br>\n",
    "- Which week was the specimen tested?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a82674b-9b90-4d49-8df1-c5e581d78ac8",
   "metadata": {},
   "source": [
    "# Exercise block C\n",
    "\n",
    "### Exercise 6: Downloading data in chunks\n",
    "We will use `batch_request` function to download data in chunks. Let's execute cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a0e635-86d4-4840-82a4-895a76471a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_request(core, params, batch_size):\n",
    "    \"\"\"Calls `solr_request` multiple times with `params` to retrieve results in chunk `batch_size` rows at a time.\"\"\"\n",
    "    if \"rows\" in \"params\":\n",
    "        print(\"WARN: You have specified the `params` -> `rows` value. It will be ignored, because the data is retrieved `batch_size` rows at a time.\")\n",
    "    # Determine the total number of rows. Note that we do not request any data (rows = 0).\n",
    "    num_results, _ = solr_request(core=core, params={**params, \"start\": 0, \"rows\": 0}, silent=True)\n",
    "    # Initialise everything for data retrieval.\n",
    "    start = 0\n",
    "    chunks = []\n",
    "    # Request chunks until we have complete data.\n",
    "    with tqdm(total=num_results) as pbar:  # Initialize tqdm progress bar.\n",
    "        while start < num_results:\n",
    "            # Update progress bar with the number of rows requested.\n",
    "            pbar.update(batch_size) \n",
    "            # Request chunk. We don't need num_results anymore because it does not change.\n",
    "            _, df_chunk = solr_request(core=core, params={**params, \"start\": start, \"rows\": batch_size}, silent=True)\n",
    "            # Record chunk.\n",
    "            chunks.append(df_chunk)\n",
    "            # Increment start.\n",
    "            start += batch_size\n",
    "    # Prepare final dataframe.\n",
    "    return pd.concat(chunks, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2f7cee-a86c-4725-996a-f84424bff2b9",
   "metadata": {},
   "source": [
    "First of all, let's construct a query for cardiovascular system. In the example below we request data with following conditions:\n",
    "- `top_level_mp_term_name` field with `cardiovascular system phenotype`.\n",
    "- `effect_size` is not null.\n",
    "- `life_stage_name` is late adult.\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "Run `solr_request` function below and look at the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf433f4-d402-424d-92dc-863bd5931edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_found, df = solr_request(\n",
    "    core='genotype-phenotype',\n",
    "    params={\n",
    "        'q': 'top_level_mp_term_name:\"cardiovascular system phenotype\" AND effect_size:[* TO *] AND life_stage_name:\"Late adult\"',\n",
    "        'fl': 'allele_accession_id,life_stage_name,marker_symbol,mp_term_name,p_value,parameter_name,parameter_stable_id,phenotyping_center,statistical_method,top_level_mp_term_name,effect_size'\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a84b44-db06-4d81-9c85-8ba1be079618",
   "metadata": {},
   "source": [
    "Download the data for request above by modifying `batch_request` function below. Set `batch_size` parameter to 100. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d76df8-b761-4923-afe4-823d6bee0f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Request dataframe in chunks.\n",
    "df = batch_request(\n",
    "    core=\"genotype-phenotype\",\n",
    "    params={\n",
    "        'q': ...\n",
    "        'fl': ...\n",
    "    },\n",
    "    batch_size=...\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37911fec-918d-451c-a4aa-68dbe6a0745c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dataframe to JSON (lines) format for subsequent work. This will contain a single self contained JSON record per line.\n",
    "df.to_json(\"impc_data.json\", orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258fd213-3fd5-476e-968b-39e4d46dbd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also save as CSV, but note that fine structure such as lists and nested data will be lost.\n",
    "df.to_csv(\"impc_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69a5608-9b47-431f-b1b8-32a78bbf39f8",
   "metadata": {},
   "source": [
    "# Exercise block D\n",
    "\n",
    "### Exercise 7: Faceting Query\n",
    "We will use `facet_request` function to run faceting query. Let's execute cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9004a23a-c453-497a-8d57-d0de8c5ea6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def facet_request(core, params, silent=False):\n",
    "    \"\"\"Performs a single Solr request.\n",
    "    \n",
    "    Returns:\n",
    "        num_found: How many rows in total did the request match.\n",
    "        df: A Pandas dataframe with a portion of the request matching `start` and `rows` parameters.\n",
    "        silent: Suppress displaying the df and number of results (useful for batch requests).\n",
    "    \"\"\"\n",
    "    base_url = \"https://www.ebi.ac.uk/mi/impc/solr/\"\n",
    "    solr_url = base_url + core + \"/select\"\n",
    "\n",
    "    response = requests.get(solr_url, params=params)\n",
    "    if not silent:\n",
    "        print(f\"\\nYour request:\\n{unquote(response.request.url)}\\n\")\n",
    "    \n",
    "    # Check if the request was successful (status code 200)\n",
    "    if response.status_code == 200:\n",
    "        # Parse the JSON response\n",
    "        data = response.json()\n",
    "        num_found = data[\"response\"][\"numFound\"]\n",
    "        if not silent:\n",
    "            print(f'Number of found documents: {num_found}\\n')\n",
    "        # Extract and add faceting query results to the list\n",
    "        facet_counts = data[\"facet_counts\"][\"facet_fields\"][params[\"facet.field\"]]\n",
    "        # Initialize an empty dictionary\n",
    "        faceting_dict = {}\n",
    "        # Iterate over the list, taking pairs of elements\n",
    "        for i in range(0, len(facet_counts), 2):\n",
    "            # Assign label as key and count as value\n",
    "            label = facet_counts[i]\n",
    "            count = facet_counts[i + 1]\n",
    "            faceting_dict[label] = [count]\n",
    "        \n",
    "        # Print the resulting dictionary\n",
    "        # Convert the list of dictionaries into a DataFrame and print the DataFrame\n",
    "        df = pd.DataFrame(faceting_dict)\n",
    "        df = pd.DataFrame.from_dict(faceting_dict, orient='index', columns=['counts']).reset_index()\n",
    "\n",
    "        # Rename the columns\n",
    "        df.columns = [params[\"facet.field\"], 'count_per_category']\n",
    "        if not silent:\n",
    "            display(df)\n",
    "        return num_found, df\n",
    "    \n",
    "    else:\n",
    "        print(\"Error:\", response.status_code, response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23025eef-805e-4949-aa21-4aaaad2136e1",
   "metadata": {},
   "source": [
    "In this exercise we will be again querying the whole core. We want to count how many documents there are for each value of the `zygosity` fields. Modify query below to get this information.\n",
    "<br>\n",
    "<br>\n",
    "If you complete the exercise successfully, your total number of documents in homozygote category will be **52,606**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af132e20-6570-4521-b160-9ac2b1f88aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_found, df = facet_request(\n",
    "    core='genotype-phenotype',\n",
    "    params={\n",
    "        'q': '*:*',\n",
    "        'rows': 0,\n",
    "        'facet': 'on',\n",
    "        'facet.field': ...,\n",
    "        'facet.limit': 15,\n",
    "        'facet.mincount': 1\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508fc9f9-6d1b-4518-89ef-86fb68c0a58c",
   "metadata": {},
   "source": [
    "# Exercises: Phenodigm Core\n",
    "\n",
    "Now we will go over the disease section of the IMPC website. The `phenodigm` core contains all of the information regarding human-mouse disease associations.\n",
    "\n",
    "Some useful links are:\n",
    "- [IMPC disease models summary](https://www.mousephenotype.org/help/data-visualization/gene-pages/disease-models/)\n",
    "- [IMPC disease associations](https://www.mousephenotype.org/help/data-analysis/disease-associations/)\n",
    "- [Disease Models Portal](https://diseasemodels.research.its.qmul.ac.uk)\n",
    "- [OMIM](https://www.omim.org/)\n",
    "- [Orphanet](https://www.orpha.net)\n",
    "- [SOLR Phenodigm core documentation](https://www.ebi.ac.uk/mi/impc/solrdoc/phenodigm.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e918ce-12dc-4f91-a444-39887474dbff",
   "metadata": {},
   "source": [
    "### Exercise 1: Getting Familiar with the Phenodigm Core\n",
    "Get familiar with the structure of the phenodigm core queries. Write a query to retrieve 5 rows of the `disease_model_summary` type\n",
    "\n",
    "If you complete the exercise successfully, your total number of documents will be **8,444,376**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c30f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_found, df = solr_request(\n",
    "    core=...,\n",
    "    params={\n",
    "        'q': ...,\n",
    "        'rows': ...\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c2e890-1556-4a39-859c-f6272e224979",
   "metadata": {},
   "source": [
    "### Exercise 2: Filtering by Disease\n",
    "\n",
    "When filtering by disease, we can use the following fields:\n",
    "- `disease_term`\n",
    "- `disease_id`\n",
    "\n",
    "\n",
    "Refer to the [documentation](https://www.ebi.ac.uk/mi/impc/solrdoc/phenodigm.html) and select the most appropriate `field` to filter for the disease: *[Robinow Syndrome](https://www.omim.org/entry/618529?search=618529&highlight=618529)*\n",
    "\n",
    "How many documents are there on *Robinow Syndrome*?\n",
    "\n",
    "If you complete the exercise successfully, your total number of documents will be **11,655**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82b5a4d-b20d-48b7-935b-157615355357",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_found, df = solr_request(\n",
    "    core='phenodigm',\n",
    "    params={\n",
    "        'q': ...,\n",
    "        'rows': 5,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3395f7e6-2a80-488d-9297-ef45c841d0ba",
   "metadata": {},
   "source": [
    "### Exercise 3: Filtering Mouse Models Related to a Disease\n",
    "Retrieve the first 5 rows related to mouse models associated with *Robinow Syndrome*.\n",
    "\n",
    "Use the following fields to obtain the model information:\n",
    "- `model_id`\n",
    "- `disease_term`\n",
    "- `disease_id`\n",
    "- `marker_id`\n",
    "- `marker_symbol`\n",
    "- `model_source`\n",
    "- `model_genetic_background`\n",
    "\n",
    "If you complete the exercise successfully, your total number of documents will be **11,655** and they will only display **7 fields**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3f0bf1-f211-4166-a497-46cd24574c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_found, df = solr_request(\n",
    "    core='phenodigm',\n",
    "    params={\n",
    "        'q': 'type:disease_model_summary AND disease_term:\"Robinow Syndrome\"',\n",
    "        'rows': 5,\n",
    "        'fl': ...,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c1940c",
   "metadata": {},
   "source": [
    "## Advanced Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470e0283-2e88-4c7a-84b0-cd5358d54802",
   "metadata": {},
   "source": [
    "### Exercise 4: Calculate the Phenodigm score\n",
    "\n",
    "In this exercise, we will calculate the Phenodigm score, sort the results by this score, and filter the documents based on gene-disease curation.\n",
    "\n",
    "1. Retrieve all diseases related to the mouse gene *[Nxn](https://www.mousephenotype.org/data/genes/MGI:109331)* (MGI:109331)\n",
    "2. Select the following fields:\n",
    "    - `marker_id`\n",
    "    - `model_id`\n",
    "    - `disease_id`\n",
    "    - `disease_term`\n",
    "    - `disease_model_avg_norm`\n",
    "    - `disease_model_max_norm`\n",
    "    - `association_curated`\n",
    "3. Filter results to keep only those where `association_curated` is `true`.\n",
    "4. Calculate their **Phenodigm scores** by adding the following to your last field:\n",
    "    -  `phenodigm_score:div(sum(disease_model_avg_norm,disease_model_max_norm),2)`\n",
    "5. Sort the results in descending order by the calculated Phenodigm score by passing the following to the `sort` parameter:\n",
    "    - `div(sum(disease_model_avg_norm,disease_model_max_norm),2)`\n",
    "\n",
    "        **HINT**: do not include the text `phenodigm_score:` to the sort parameter as this will produce an error.\n",
    "\n",
    "If you complete the exercise successfully, your total number of documents will be **48**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f83a21-ac7e-42e9-b60c-60bc75c09f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_found, df = solr_request(\n",
    "    core='phenodigm',\n",
    "    params={\n",
    "        'q': 'type:disease_model_summary AND marker_id:\"MGI:109331\" AND association_curated:true',\n",
    "        'fl': 'marker_id,model_id,disease_id,disease_term,disease_model_avg_norm,disease_model_max_norm,association_curated,phenodigm_score:div(sum(disease_model_avg_norm,disease_model_max_norm),2)',\n",
    "        'sort':'div(sum(disease_model_avg_norm,disease_model_max_norm),2) desc'\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89acbf3f-2490-4438-b250-90f5efdf9af5",
   "metadata": {},
   "source": [
    "\n",
    "### Exercise 5: Iterate over a list of diseases or models/ genes\n",
    "Now, we will define another helper function, `iterator_solr_request`. This function will request information for a list of values of a given `field`. This is particularly useful when we want to request data for specific models or genes.\n",
    "\n",
    "Execute the helper functions below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc86728-aee8-44ac-a73c-4433286e00ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Helper function to fetch results. This function is used by the 'iterator_solr_request' function.\n",
    "def entity_iterator(base_url, params):\n",
    "    \"\"\"Generator function to fetch results from the SOLR server in chunks using pagination\n",
    "\n",
    "    Args:\n",
    "        base_url (str): The base URL of the Solr server to fetch documents from.\n",
    "        params (dict): A dictionary of parameters to include in the GET request. Must include\n",
    "                       'start' and 'rows' keys, which represent the index of the first document\n",
    "                       to fetch and the number of documents to fetch per request, respectively.\n",
    "\n",
    "    Yields:\n",
    "        dict: The next document in the response from the Solr server.\n",
    "    \"\"\"\n",
    "    # Initialise variable to check the first request\n",
    "    first_request = True\n",
    "\n",
    "    # Call the API in chunks and yield the documents in each chunk\n",
    "    while True:\n",
    "        response = requests.get(base_url, params=params)\n",
    "        data = response.json()\n",
    "        docs = data[\"response\"][\"docs\"]\n",
    "\n",
    "        # Print the first request only\n",
    "        if first_request:\n",
    "            print(f'Your first request: {response.url}')\n",
    "            first_request = False\n",
    "\n",
    "        # Yield the documents in the current chunk\n",
    "        for doc in docs:\n",
    "            yield doc\n",
    "\n",
    "        # Check if there are more results to fetch\n",
    "        start = params[\"start\"] + params[\"rows\"]\n",
    "        num_found = data[\"response\"][\"numFound\"]\n",
    "        if start >= num_found:\n",
    "            break\n",
    "\n",
    "        # Update the start parameter for the next request\n",
    "        params[\"start\"] = start\n",
    "\n",
    "    # Print last request and total number of documents retrieved\n",
    "    print(f'Your last request: {response.url}')\n",
    "    print(f'Number of found documents: {data[\"response\"][\"numFound\"]}\\n')\n",
    "\n",
    "# Function to iterate over field list and write results to a file.\n",
    "def iterator_solr_request(core, params, filename='iteration_solr_request', format='json'):\n",
    "    \"\"\"Function to fetch results in batches from the Solr API and write them to a file\n",
    "        Defaults to fetching 5000 rows at a time.\n",
    "\n",
    "    Args:\n",
    "        core (str): The name of the Solr core to fetch results from.\n",
    "        params (dict): A dictionary of parameters to use in the filter query. Must include\n",
    "                       'field_list' and 'field_type' keys, which represent the list of field items (i.e., list of MGI model identifiers)\n",
    "                        to fetch and the type of the field (i.e., model_id) to filter on, respectively.\n",
    "        filename (str): The name of the file to write the results to. Defaults to 'iteration_solr_request'.\n",
    "        format (str): The format of the output file. Can be 'csv' or 'json'. Defaults to 'json'.\n",
    "    \"\"\"\n",
    "\n",
    "    # Validate format\n",
    "    if format not in ['json','csv']:\n",
    "        raise ValueError(\"Invalid format. Please use 'json' or 'csv'\")\n",
    "    \n",
    "    # Base URL\n",
    "    base_url = \"https://www.ebi.ac.uk/mi/impc/solr/\"\n",
    "    solr_url = base_url + core + \"/select\"\n",
    "\n",
    "    # Extract entities_list and entity_type from params\n",
    "    field_list = params.pop(\"field_list\")\n",
    "    field_type = params.pop(\"field_type\")\n",
    "\n",
    "    # Construct the filter query with grouped model IDs\n",
    "    fq = \"{}:({})\".format(\n",
    "        field_type, \" OR \".join(['\"{}\"'.format(id) for id in field_list])\n",
    "    )\n",
    "\n",
    "    # Show users the field and field values they passed to the function\n",
    "    print(\"Queried field:\",fq)\n",
    "    # Set internal params the users should not change\n",
    "    params[\"fq\"] = fq\n",
    "    params[\"wt\"] = 'json'\n",
    "    params[\"start\"]=0 # Start at the first result\n",
    "    params[\"rows\"]=5000 # Fetch results in chunks of 5000\n",
    "\n",
    "\n",
    "    try:\n",
    "        # Fetch results using a generator function\n",
    "        results_generator = entity_iterator(solr_url, params)\n",
    "    except Exception as e:\n",
    "        raise Exception(\"An error occurred while downloading the data: \" + str(e))\n",
    "\n",
    "    # Append extension to the filename\n",
    "    filename = f\"{filename}.{format}\"\n",
    "\n",
    "    try:\n",
    "        # Open the file in write mode\n",
    "        with open(filename, \"w\", newline=\"\") as f:\n",
    "            if format == 'csv':\n",
    "                writer = None\n",
    "                for item in results_generator:\n",
    "                    # Initialize the CSV writer with the keys of the first item as the field names\n",
    "                    if writer is None:\n",
    "                        writer = csv.DictWriter(f, fieldnames=item.keys())\n",
    "                        writer.writeheader()\n",
    "                    # Write the item to the CSV file\n",
    "                    writer.writerow(item)\n",
    "                    # Write to json without loading to memory.\n",
    "            elif format == 'json':\n",
    "                f.write('[')\n",
    "                for i, item in enumerate(results_generator):\n",
    "                    if i != 0:\n",
    "                        f.write(',')\n",
    "                    json.dump(item, f)\n",
    "                f.write(']')\n",
    "    except Exception as e:\n",
    "        raise Exception(\"An error occurred while writing the file: \" + str(e))\n",
    "\n",
    "    print(f\"File {filename} was created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9a3482-e904-48aa-b6a2-78524639c3d4",
   "metadata": {},
   "source": [
    "Here is how to use it:\n",
    "- New information required from the user:\n",
    "    - `field_list`: A list of field names to be queried in the API. (e.g., MGI ids, OMIM ids, gene ids).\n",
    "    - `field_type`: The type of `field` we are querying. (e.g., `model_id`, `disease_id`, `marker_id`).\n",
    "    - `filename`: The name of the file you wish to save the data in.\n",
    "    - `format`: The format in which you want to save the data (e.g., `json`, `csv`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01f2005-7a88-4c13-8475-fc987dbe45d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of model IDs.\n",
    "models = [\"MGI:3587188\",\"MGI:3587185\",\"MGI:3605874\",\"MGI:2668213\"]\n",
    "\n",
    "# Call iterator function\n",
    "iterator_solr_request(\n",
    "    core='phenodigm', \n",
    "        params = {\n",
    "        'q': 'type:disease_model_summary',  \n",
    "        'fl': 'model_id,marker_id,disease_id',\n",
    "        'field_list': models,\n",
    "        'field_type': 'model_id'\n",
    "    },\n",
    "    filename='model_ids',\n",
    "    format='json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad992401-5ea0-4d16-8777-1a69ce5840b7",
   "metadata": {},
   "source": [
    "### Bonus exercise\n",
    "Now, build your own request based on the example above, incorporating the following changes:\n",
    "1. Use the `genotype-phenotype` core\n",
    "2. Iterate over genes (the name of the field is `marker_symbol`)\n",
    "3. Use the following list of genes: _Zfp580, Firrm, Gpld1, Mbip_\n",
    "4. Modify the list of fields you request (`fl`) to include:\n",
    "    - `marker_symbol`\n",
    "    - `allele_symbol`\n",
    "    - `parameter_stable_id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3586796f-9cbe-4030-ac26-4282025ebb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genes example\n",
    "genes = [\"Zfp580\",\"Firrm\",\"Gpld1\",\"Mbip\"]\n",
    "\n",
    "# Initial query parameters\n",
    "params = {\n",
    "    'q': \"*:*\",\n",
    "    'fl': 'marker_symbol,allele_symbol,parameter_stable_id',\n",
    "    'field_list': ...,\n",
    "    'field_type': ...\n",
    "}\n",
    "iterator_solr_request(core=..., params=params, filename= ..., format =...)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
